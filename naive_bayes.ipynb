{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('Predict_Academic_Success_Modified.csv')\n",
    "\n",
    "# Convert categorical columns to numerical using Label Encoding\n",
    "categorical_columns = [\"Previous qualification\", \"Mother's qualification\", \"Father's qualification\", \"Nacionality\",\n",
    "                    \"Mother's occupation\", \"Father's occupation\", \"Marital status\", \"Application mode\",\n",
    "                    \"Course\", \"Daytime/evening attendance\", \"Displaced\", \"Educational special needs\", \n",
    "                    \"Debtor\", \"Tuition fees up to date\", \"Gender\", \"Scholarship holder\", \"International\"]\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le  # Save encoder in case we need to transform new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target using Label Encoding ('Dropout', 'Enrolled', 'Graduate')\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Target\"] = label_encoder.fit_transform(data[\"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90% for training/testing, 10% for unseen validation\n",
    "train_test_data, unseen_data = train_test_split(data, test_size=0.10, random_state=42, stratify=data[\"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 90% into 80% training and 20% testing\n",
    "train_data, test_data = train_test_split(\n",
    "    train_test_data, test_size=0.20, random_state=42, stratify=train_test_data[\"Target\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variables\n",
    "X_train = train_data.drop(columns=[\"Target\"])\n",
    "y_train = train_data[\"Target\"]\n",
    "X_test = test_data.drop(columns=[\"Target\"])\n",
    "y_test = test_data[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Naive Bayes model\n",
    "nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy scores: \n",
      "[0.70532915 0.66144201 0.69592476 0.68338558 0.72641509 0.76100629\n",
      " 0.69496855 0.64779874 0.68553459 0.73899371]\n",
      "\n",
      "Mean cross-validation accuracy: \n",
      "0.7000798485834269\n",
      "\n",
      "\n",
      "Evaluation Metrics:\n",
      "    Metric    Score\n",
      " Accuracy: 0.691343\n",
      "Precision: 0.678075\n",
      "   Recall: 0.691343\n",
      "  ROC-AUC: 0.793278\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "          Dropout  Enrolled  Graduate\n",
      "Dropout       169        42        45\n",
      "Enrolled       29        46        68\n",
      "Graduate       36        26       336\n"
     ]
    }
   ],
   "source": [
    "# Apply 10-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cross_val_scores = cross_val_score(nb_model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "print(f\"Cross-validation accuracy scores: \\n{cross_val_scores}\\n\")\n",
    "print(f\"Mean cross-validation accuracy: \\n{cross_val_scores.mean()}\\n\")\n",
    "\n",
    "# Train the model\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, nb_model.predict_proba(X_test), multi_class=\"ovr\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame for the evaluation metrics\n",
    "results_df = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy:\", \"Precision:\", \"Recall:\", \"ROC-AUC:\"],\n",
    "    \"Score\": [accuracy, precision, recall, roc_auc]\n",
    "})\n",
    "\n",
    "# Print the results in tabular form\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Get class labels from the LabelEncoder\n",
    "class_labels = label_encoder.classes_\n",
    "\n",
    "# Create a DataFrame for the confusion matrix\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_labels, columns=class_labels)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(conf_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the unseen 10% dataset\n",
    "X_unseen = unseen_data.drop(columns=[\"Target\"])\n",
    "y_unseen = unseen_data[\"Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained model to predict outcomes for the unseen data\n",
    "y_unseen_pred = nb_model.predict(X_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unseen Data Evaluation Metrics:\n",
      "   Metric    Score\n",
      " Accuracy 0.683973\n",
      "Precision 0.689478\n",
      "   Recall 0.683973\n",
      "  ROC-AUC 0.829791\n",
      "\n",
      "Confusion Matrix for Unseen Data:\n",
      "\n",
      "          Dropout  Enrolled  Graduate\n",
      "Dropout        94        33        15\n",
      "Enrolled       13        27        40\n",
      "Graduate       14        25       182\n",
      "\n",
      "Evaluation Matrix for Unseen Data:\n",
      "\n",
      "Category  Matches  Mismatches\n",
      " Dropout       94          48\n",
      "Enrolled       27          53\n",
      "Graduate      182          39\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "unseen_accuracy = accuracy_score(y_unseen, y_unseen_pred)\n",
    "\n",
    "# Precision\n",
    "unseen_precision = precision_score(y_unseen, y_unseen_pred, average='weighted')\n",
    "\n",
    "# Recall\n",
    "unseen_recall = recall_score(y_unseen, y_unseen_pred, average='weighted')\n",
    "\n",
    "# ROC-AUC Score\n",
    "unseen_roc_auc = roc_auc_score(y_unseen, nb_model.predict_proba(X_unseen), multi_class=\"ovr\")\n",
    "\n",
    "# Confusion Matrix\n",
    "unseen_conf_matrix = confusion_matrix(y_unseen, y_unseen_pred)\n",
    "\n",
    "# Create evaluation metrics DataFrame\n",
    "unseen_results_df = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"ROC-AUC\"],\n",
    "    \"Score\": [unseen_accuracy, unseen_precision, unseen_recall, unseen_roc_auc]\n",
    "})\n",
    "\n",
    "print(\"\\nUnseen Data Evaluation Metrics:\")\n",
    "print(unseen_results_df.to_string(index=False))\n",
    "\n",
    "# Display Confusion Matrix\n",
    "unseen_conf_matrix_df = pd.DataFrame(unseen_conf_matrix, \n",
    "                                     index=label_encoder.classes_, \n",
    "                                     columns=label_encoder.classes_)\n",
    "\n",
    "print(\"\\nConfusion Matrix for Unseen Data:\\n\")\n",
    "print(unseen_conf_matrix_df)\n",
    "\n",
    "# Calculate matches (diagonal values)\n",
    "matches = np.diag(unseen_conf_matrix)\n",
    "\n",
    "# Calculate mismatches (row sum - diagonal)\n",
    "mismatches = unseen_conf_matrix.sum(axis=1) - matches\n",
    "\n",
    "# Create reformatted confusion matrix DataFrame\n",
    "unseen_conf_summary_df = pd.DataFrame({\n",
    "    \"Category\": label_encoder.classes_,\n",
    "    \"Matches\": matches,\n",
    "    \"Mismatches\": mismatches\n",
    "})\n",
    "\n",
    "print(\"\\nEvaluation Matrix for Unseen Data:\\n\")\n",
    "print(unseen_conf_summary_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
